{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "robust-motivation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# set seed\n",
    "seed = 24\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "# Define data path\n",
    "DATA_PATH = \"../data/\"\n",
    "#os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "defensive-japan",
   "metadata": {},
   "outputs": [],
   "source": [
    "pids = pickle.load(open('pids.pkl', 'rb'))\n",
    "vids = pickle.load(open('vids.pkl', 'rb'))\n",
    "seqs = pickle.load(open('seqs.pkl', 'rb'))\n",
    "types = pickle.load(open('types.pkl', 'rb'))\n",
    "rtypes = pickle.load(open('rtypes.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8fffb22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1279"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "objective-dairy",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim=256, hid_dim=128):\n",
    "        super(RNN, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.rnn = nn.GRU(emb_dim, hid_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hid_dim, vocab_size, bias=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, codes):\n",
    "        emb_list = []\n",
    "        for code in codes:\n",
    "            emb = self.embeddings(torch.tensor(code))\n",
    "            emb_mean = emb.mean(dim=0).unsqueeze(dim=0)\n",
    "            emb_list.append(emb_mean)\n",
    "        emb_seq = torch.cat(emb_list, dim=0).unsqueeze(dim=0)\n",
    "        output, _ = self.rnn(emb_seq)\n",
    "        result = F.relu(output)\n",
    "        result = self.fc(result)\n",
    "        return result[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "mediterranean-squad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(seed)\n",
    "\n",
    "training_index = random.sample(range(len(seqs)), k=int(len(seqs)*0.8))\n",
    "test_index = list(set(range(len(seqs))) - set(training_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "satisfied-metro",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_med = 1279"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "turned-party",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(vocab_size=vocab_med)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "shaped-collectible",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataFormatter(patient_list):\n",
    "\n",
    "    x = []\n",
    "    for codes in patient_list:\n",
    "        x.append(codes)\n",
    "    target = np.zeros((1, vocab_med))\n",
    "    target[0, x[-1]] = 1\n",
    "    return x[:-1], torch.FloatTensor(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "complimentary-greeting",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "\n",
    "def eval_model(model, data_index):\n",
    "    model.eval()\n",
    "    p, r, f = np.array([]), np.array([]), np.array([])\n",
    "    model.eval()\n",
    "    for p_index in data_index:\n",
    "        patient = seqs[p_index]\n",
    "        for idx, visit in enumerate(patient):\n",
    "            if idx > 0:\n",
    "                x, y = dataFormatter(patient[:idx+1])\n",
    "                y_hat = model(x)\n",
    "                y_hat = (y_hat > 0.5).int()\n",
    "                y = y.squeeze()\n",
    "                y_hat = y_hat.squeeze()\n",
    "                new_p, new_r, new_f, _ = precision_recall_fscore_support(y, y_hat, average='binary', zero_division=1)\n",
    "                p, r, f = np.append(p, new_p), np.append(r, new_r), np.append(f, new_f)\n",
    "\n",
    "    return np.mean(p), np.mean(r), np.mean(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "lesser-madonna",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def train(training_index, val_index):\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for p_index in training_index:\n",
    "            loss = 0\n",
    "            patient = seqs[p_index]\n",
    "            for idx, visit in enumerate(patient):\n",
    "                if idx > 0:\n",
    "                    x, target = dataFormatter(patient[:idx+1])\n",
    "                    multi_target = np.full((1, vocab_med), -1)\n",
    "                    for idx, item in enumerate(visit):\n",
    "                        multi_target[0][idx] = item\n",
    "                    multi_target = torch.LongTensor(multi_target)\n",
    "                    pred = model(x)\n",
    "\n",
    "                    loss += F.binary_cross_entropy_with_logits(pred, target)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss = loss.item()\n",
    "        train_loss = train_loss / len(training_index)\n",
    "        print('Epoch: {} \\t Training Loss: {:.6f}'.format(epoch+1, train_loss))\n",
    "        p, r, f = eval_model(model, val_index)\n",
    "        print('Epoch: {} \\t Validation p: {:.2f}, r:{:.2f}, f: {:.2f}'\n",
    "              .format(epoch+1, p, r, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1196e04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model_top_k(model, data_index, k):\n",
    "    model.eval()\n",
    "    y_pred = torch.LongTensor()\n",
    "    y_true = torch.LongTensor()\n",
    "    scores = torch.LongTensor()\n",
    "    model.eval()\n",
    "    for p_index in data_index:\n",
    "        patient = seqs[p_index]\n",
    "        for idx, visit in enumerate(patient):\n",
    "            if idx > 0:\n",
    "                x, y = dataFormatter(patient[:idx+1])\n",
    "                y_hat = model(x)\n",
    "                y_hat = (y_hat > 0.5).int()\n",
    "                scores = torch.cat((scores, torch.mul(y_hat, y).sum(dim=1)), 0)\n",
    "                y_pred = torch.cat((y_pred,  y_hat.detach().to('cpu')), dim=0)\n",
    "                y_true = torch.cat((y_true, y.detach().to('cpu')), dim=0)\n",
    "    \n",
    "    top_k = torch.topk(scores, k).indices\n",
    "    y_true = torch.reshape(y_true[top_k, :], (-1,))\n",
    "    y_pred = torch.reshape(y_pred[top_k, :], (-1,))\n",
    "    result = torch.mul(y_true, y_pred).sum(0) / y_true.sum(dim=0)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "alleged-plane",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \t Training Loss: 0.000038\n",
      "Epoch: 1 \t Validation p: 0.77, r:0.20, f: 0.30\n",
      "Epoch: 2 \t Training Loss: 0.000038\n",
      "Epoch: 2 \t Validation p: 0.77, r:0.25, f: 0.35\n",
      "Epoch: 3 \t Training Loss: 0.000038\n",
      "Epoch: 3 \t Validation p: 0.77, r:0.27, f: 0.37\n",
      "Epoch: 4 \t Training Loss: 0.000038\n",
      "Epoch: 4 \t Validation p: 0.78, r:0.28, f: 0.39\n",
      "Epoch: 5 \t Training Loss: 0.000038\n",
      "Epoch: 5 \t Validation p: 0.79, r:0.29, f: 0.40\n",
      "Epoch: 6 \t Training Loss: 0.000037\n",
      "Epoch: 6 \t Validation p: 0.79, r:0.30, f: 0.41\n",
      "Epoch: 7 \t Training Loss: 0.000037\n",
      "Epoch: 7 \t Validation p: 0.80, r:0.31, f: 0.42\n",
      "Epoch: 8 \t Training Loss: 0.000037\n",
      "Epoch: 8 \t Validation p: 0.80, r:0.32, f: 0.43\n",
      "Epoch: 9 \t Training Loss: 0.000037\n",
      "Epoch: 9 \t Validation p: 0.81, r:0.33, f: 0.44\n",
      "Epoch: 10 \t Training Loss: 0.000036\n",
      "Epoch: 10 \t Validation p: 0.81, r:0.34, f: 0.45\n",
      "Epoch: 11 \t Training Loss: 0.000037\n",
      "Epoch: 11 \t Validation p: 0.81, r:0.35, f: 0.47\n",
      "Epoch: 12 \t Training Loss: 0.000036\n",
      "Epoch: 12 \t Validation p: 0.82, r:0.36, f: 0.48\n",
      "Epoch: 13 \t Training Loss: 0.000035\n",
      "Epoch: 13 \t Validation p: 0.81, r:0.38, f: 0.50\n",
      "Epoch: 14 \t Training Loss: 0.000036\n",
      "Epoch: 14 \t Validation p: 0.82, r:0.39, f: 0.50\n",
      "Epoch: 15 \t Training Loss: 0.000036\n",
      "Epoch: 15 \t Validation p: 0.81, r:0.40, f: 0.52\n",
      "Epoch: 16 \t Training Loss: 0.000035\n",
      "Epoch: 16 \t Validation p: 0.82, r:0.41, f: 0.52\n",
      "Epoch: 17 \t Training Loss: 0.000034\n",
      "Epoch: 17 \t Validation p: 0.82, r:0.41, f: 0.53\n",
      "Epoch: 18 \t Training Loss: 0.000035\n",
      "Epoch: 18 \t Validation p: 0.82, r:0.42, f: 0.54\n",
      "Epoch: 19 \t Training Loss: 0.000033\n",
      "Epoch: 19 \t Validation p: 0.82, r:0.43, f: 0.55\n",
      "Epoch: 20 \t Training Loss: 0.000033\n",
      "Epoch: 20 \t Validation p: 0.82, r:0.44, f: 0.55\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "train(training_index, training_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "portable-destruction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation p: 0.65, r:0.33, f: 0.40\n"
     ]
    }
   ],
   "source": [
    "p, r, f = eval_model(model, test_index)\n",
    "print('Validation p: {:.2f}, r:{:.2f}, f: {:.2f}'.format(p, r, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0dfed558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy@5: 0.55\n",
      "Validation Accuracy@10: 0.53\n",
      "Validation Accuracy@15: 0.53\n",
      "Validation Accuracy@20: 0.55\n",
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for k in [5, 10, 15, 20]:\n",
    "    acc_k = eval_model_top_k(model, test_index, k)\n",
    "    print('Validation Accuracy@' + str(k) + ': {:.2f}'.format(acc_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "antique-divide",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc_k: 0.59\n"
     ]
    }
   ],
   "source": [
    "acc_k = eval_model_top_k(model, test_index, 3)\n",
    "print('Validation acc_k: {:.2f}'.format(acc_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89459dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
