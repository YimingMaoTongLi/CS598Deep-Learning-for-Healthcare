{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "found-genre",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# set seed\n",
    "seed = 24\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "genuine-dinner",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = pickle.load(open('seqs.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "rocky-humor",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlphaAttention(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.a_att = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, g):\n",
    "        alpha = torch.softmax(self.a_att(g), dim=1)\n",
    "        return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "roman-defendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BetaAttention(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.b_att = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, h):\n",
    "        beta = torch.tanh(self.b_att(h))\n",
    "        return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "hindu-healthcare",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RETAIN(nn.Module):\n",
    "    def __init__(self, num_codes, embedding_dim=128):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_codes, embedding_dim)\n",
    "        self.rnn_a = nn.GRU(embedding_dim, embedding_dim, batch_first=True)\n",
    "        self.rnn_b = nn.GRU(embedding_dim, embedding_dim, batch_first=True)\n",
    "        self.att_a = AlphaAttention(embedding_dim)\n",
    "        self.att_b = BetaAttention(embedding_dim)\n",
    "        self.fc = nn.Linear(embedding_dim, num_codes)\n",
    "        self.sigmod = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        rev_x = list(reversed(x))\n",
    "        emb_list = []\n",
    "        for code in rev_x:\n",
    "            emb = self.embedding(torch.tensor(code))\n",
    "            emb_mean = emb.mean(dim=0).unsqueeze(dim=0)\n",
    "            emb_list.append(emb_mean)\n",
    "        rev_x = torch.cat(emb_list, dim=0).unsqueeze(dim=0)\n",
    "\n",
    "        g, _ = self.rnn_a(rev_x)\n",
    "        h, _ = self.rnn_b(rev_x)\n",
    "        alpha = self.att_a(g)\n",
    "        beta = self.att_b(h)\n",
    "        weights = torch.mul(alpha, beta)\n",
    "        c = torch.mul(weights, rev_x).sum(dim=1)\n",
    "        logits = self.fc(c)\n",
    "        return self.sigmod(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "wrong-limit",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(seed)\n",
    "\n",
    "training_index = random.sample(range(len(seqs)), k=int(len(seqs)*0.8))\n",
    "test_index = list(set(range(len(seqs))) - set(training_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "middle-turtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_med = 1279"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "surface-fight",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RETAIN(num_codes=vocab_med)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ready-corruption",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataFormatter(patient_list):\n",
    "    x = []\n",
    "    for codes in patient_list:\n",
    "        x.append(codes)\n",
    "    target = np.zeros((1, vocab_med))\n",
    "    target[0, x[-1]] = 1\n",
    "    return x[:-1], torch.FloatTensor(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "stunning-system",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "\n",
    "# def eval_model(model, data_index):\n",
    "#     model.eval()\n",
    "#     y_pred = torch.LongTensor()\n",
    "#     y_true = torch.LongTensor()\n",
    "    \n",
    "#     model.eval()\n",
    "#     for p_index in data_index:\n",
    "#         patient = seqs[p_index]\n",
    "#         for idx, visit in enumerate(patient):\n",
    "#             if idx > 0:\n",
    "#                 x, y = dataFormatter(patient[:idx+1])\n",
    "#                 y_hat = model(x)\n",
    "#                 y_hat = (y_hat > 0.5).int()\n",
    "#                 y_pred = torch.cat((y_pred,  y_hat.detach().to('cpu')), dim=0)\n",
    "#                 y_true = torch.cat((y_true, y.detach().to('cpu')), dim=0)\n",
    "#     p, r, f, _ = precision_recall_fscore_support(y_true, y_pred, average='samples')\n",
    "\n",
    "#     return p, r, f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "alike-providence",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "\n",
    "def eval_model(model, data_index):\n",
    "    model.eval()\n",
    "    p, r, f = np.array([]), np.array([]), np.array([])\n",
    "    model.eval()\n",
    "    for p_index in data_index:\n",
    "        patient = seqs[p_index]\n",
    "        for idx, visit in enumerate(patient):\n",
    "            if idx > 0:\n",
    "                x, y = dataFormatter(patient[:idx+1])\n",
    "                y_hat = model(x)\n",
    "                y_hat = (y_hat > 0.5).int()\n",
    "                y = y.squeeze()\n",
    "                y_hat = y_hat.squeeze()\n",
    "                new_p, new_r, new_f, _ = precision_recall_fscore_support(y, y_hat, average='binary', zero_division=1)\n",
    "                p, r, f = np.append(p, new_p), np.append(r, new_r), np.append(f, new_f)\n",
    "\n",
    "    return np.mean(p), np.mean(r), np.mean(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "official-bundle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def train(training_index, val_index):\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for p_index in training_index:\n",
    "            loss = 0\n",
    "            patient = seqs[p_index]\n",
    "            for idx, visit in enumerate(patient):\n",
    "                if idx > 0:\n",
    "                    x, target = dataFormatter(patient[:idx+1])\n",
    "                    multi_target = np.full((1, vocab_med), -1)\n",
    "                    for idx, item in enumerate(visit):\n",
    "                        multi_target[0][idx] = item\n",
    "                    multi_target = torch.LongTensor(multi_target)\n",
    "                    pred = model(x)\n",
    "                    loss += F.binary_cross_entropy_with_logits(pred, target)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss = loss.item()\n",
    "        train_loss = train_loss / len(training_index)\n",
    "        print('Epoch: {} \\t Training Loss: {:.6f}'.format(epoch+1, train_loss))\n",
    "        p, r, f = eval_model(model, val_index)\n",
    "        print('Epoch: {} \\t Validation p: {:.2f}, r:{:.2f}, f: {:.2f}'\n",
    "              .format(epoch+1, p, r, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "754269fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model_top_k(model, data_index, k):\n",
    "    model.eval()\n",
    "    y_pred = torch.LongTensor()\n",
    "    y_true = torch.LongTensor()\n",
    "    scores = torch.LongTensor()\n",
    "    model.eval()\n",
    "    for p_index in data_index:\n",
    "        patient = seqs[p_index]\n",
    "        for idx, visit in enumerate(patient):\n",
    "            if idx > 0:\n",
    "                x, y = dataFormatter(patient[:idx+1])\n",
    "                y_hat = model(x)\n",
    "                y_hat = (y_hat > 0.5).int()\n",
    "                scores = torch.cat((scores, torch.mul(y_hat, y).sum(dim=1)), 0)\n",
    "                y_pred = torch.cat((y_pred,  y_hat.detach().to('cpu')), dim=0)\n",
    "                y_true = torch.cat((y_true, y.detach().to('cpu')), dim=0)\n",
    "    \n",
    "    top_k = torch.topk(scores, k).indices\n",
    "    y_true = torch.reshape(y_true[top_k, :], (-1,))\n",
    "    y_pred = torch.reshape(y_pred[top_k, :], (-1,))\n",
    "    result = torch.mul(y_true, y_pred).sum(0) / y_true.sum(dim=0)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "brown-development",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \t Training Loss: 0.000345\n",
      "Epoch: 1 \t Validation p: 0.73, r:0.18, f: 0.27\n",
      "Epoch: 2 \t Training Loss: 0.000345\n",
      "Epoch: 2 \t Validation p: 0.76, r:0.18, f: 0.28\n",
      "Epoch: 3 \t Training Loss: 0.000345\n",
      "Epoch: 3 \t Validation p: 0.77, r:0.18, f: 0.28\n",
      "Epoch: 4 \t Training Loss: 0.000345\n",
      "Epoch: 4 \t Validation p: 0.78, r:0.19, f: 0.29\n",
      "Epoch: 5 \t Training Loss: 0.000345\n",
      "Epoch: 5 \t Validation p: 0.78, r:0.20, f: 0.30\n",
      "Epoch: 6 \t Training Loss: 0.000345\n",
      "Epoch: 6 \t Validation p: 0.79, r:0.20, f: 0.30\n",
      "Epoch: 7 \t Training Loss: 0.000345\n",
      "Epoch: 7 \t Validation p: 0.79, r:0.21, f: 0.31\n",
      "Epoch: 8 \t Training Loss: 0.000345\n",
      "Epoch: 8 \t Validation p: 0.79, r:0.21, f: 0.32\n",
      "Epoch: 9 \t Training Loss: 0.000345\n",
      "Epoch: 9 \t Validation p: 0.79, r:0.22, f: 0.32\n",
      "Epoch: 10 \t Training Loss: 0.000345\n",
      "Epoch: 10 \t Validation p: 0.80, r:0.22, f: 0.32\n",
      "Epoch: 11 \t Training Loss: 0.000345\n",
      "Epoch: 11 \t Validation p: 0.80, r:0.23, f: 0.33\n",
      "Epoch: 12 \t Training Loss: 0.000345\n",
      "Epoch: 12 \t Validation p: 0.80, r:0.23, f: 0.33\n",
      "Epoch: 13 \t Training Loss: 0.000345\n",
      "Epoch: 13 \t Validation p: 0.81, r:0.23, f: 0.33\n",
      "Epoch: 14 \t Training Loss: 0.000345\n",
      "Epoch: 14 \t Validation p: 0.81, r:0.23, f: 0.34\n",
      "Epoch: 15 \t Training Loss: 0.000345\n",
      "Epoch: 15 \t Validation p: 0.81, r:0.24, f: 0.34\n",
      "Epoch: 16 \t Training Loss: 0.000345\n",
      "Epoch: 16 \t Validation p: 0.81, r:0.24, f: 0.35\n",
      "Epoch: 17 \t Training Loss: 0.000345\n",
      "Epoch: 17 \t Validation p: 0.81, r:0.24, f: 0.35\n",
      "Epoch: 18 \t Training Loss: 0.000345\n",
      "Epoch: 18 \t Validation p: 0.81, r:0.24, f: 0.35\n",
      "Epoch: 19 \t Training Loss: 0.000345\n",
      "Epoch: 19 \t Validation p: 0.82, r:0.24, f: 0.36\n",
      "Epoch: 20 \t Training Loss: 0.000345\n",
      "Epoch: 20 \t Validation p: 0.82, r:0.25, f: 0.36\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "train(training_index, training_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "changing-benefit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation p: 0.74, r:0.22, f: 0.32\n"
     ]
    }
   ],
   "source": [
    "p, r, f = eval_model(model, test_index)\n",
    "print('Validation p: {:.2f}, r:{:.2f}, f: {:.2f}'.format(p, r, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "separated-pipeline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy@5: 0.36\n",
      "Validation Accuracy@10: 0.32\n",
      "Validation Accuracy@15: 0.32\n",
      "Validation Accuracy@20: 0.32\n",
      "Wall time: 1min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for k in [5, 10, 15, 20]:\n",
    "    acc_k = eval_model_top_k(model, test_index, k)\n",
    "    print('Validation Accuracy@' + str(k) + ': {:.2f}'.format(acc_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8e0094cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc_k: 0.34\n"
     ]
    }
   ],
   "source": [
    "acc_k = eval_model_top_k(model, test_index, 3)\n",
    "print('Validation acc_k: {:.2f}'.format(acc_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a23f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
